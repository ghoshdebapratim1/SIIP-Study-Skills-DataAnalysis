{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e4ebe630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fancyimpute"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\Users\\debap\\AppData\\Local\\Continuum\\anaconda3\\python.exe' 'C:\\Users\\debap\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py' build_wheel 'C:\\Users\\debap\\AppData\\Local\\Temp\\tmpkycyq_qe'\n",
      "       cwd: C:\\Users\\debap\\AppData\\Local\\Temp\\pip-install-bb8_tfxw\\cvxopt_291ea25f5bfb4d79b838c4c18bf32643\n",
      "  Complete output (19 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-37\n",
      "  creating build\\lib.win-amd64-cpython-37\\cvxopt\n",
      "  copying src\\python\\coneprog.py -> build\\lib.win-amd64-cpython-37\\cvxopt\n",
      "  copying src\\python\\cvxprog.py -> build\\lib.win-amd64-cpython-37\\cvxopt\n",
      "  copying src\\python\\info.py -> build\\lib.win-amd64-cpython-37\\cvxopt\n",
      "  copying src\\python\\misc.py -> build\\lib.win-amd64-cpython-37\\cvxopt\n",
      "  copying src\\python\\modeling.py -> build\\lib.win-amd64-cpython-37\\cvxopt\n",
      "  copying src\\python\\msk.py -> build\\lib.win-amd64-cpython-37\\cvxopt\n",
      "  copying src\\python\\printing.py -> build\\lib.win-amd64-cpython-37\\cvxopt\n",
      "  copying src\\python\\solvers.py -> build\\lib.win-amd64-cpython-37\\cvxopt\n",
      "  copying src\\python\\_version.py -> build\\lib.win-amd64-cpython-37\\cvxopt\n",
      "  copying src\\python\\__init__.py -> build\\lib.win-amd64-cpython-37\\cvxopt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading fancyimpute-0.7.0.tar.gz (25 kB)\n",
      "Collecting knnimpute>=0.1.0\n",
      "  Downloading knnimpute-0.1.0.tar.gz (8.3 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.24.2 in c:\\users\\debap\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from fancyimpute) (1.0.1)\n",
      "Collecting cvxpy\n",
      "  Downloading cvxpy-1.3.1-cp37-cp37m-win_amd64.whl (889 kB)\n",
      "Collecting cvxopt\n",
      "  Downloading cvxopt-1.3.1.tar.gz (4.0 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: pytest in c:\\users\\debap\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from fancyimpute) (6.2.4)\n",
      "Requirement already satisfied: nose in c:\\users\\debap\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from fancyimpute) (1.3.7)\n",
      "Requirement already satisfied: six in c:\\users\\debap\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from knnimpute>=0.1.0->fancyimpute) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.10 in c:\\users\\debap\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from knnimpute>=0.1.0->fancyimpute) (1.21.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\debap\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from scikit-learn>=0.24.2->fancyimpute) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\debap\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from scikit-learn>=0.24.2->fancyimpute) (3.0.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\debap\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from scikit-learn>=0.24.2->fancyimpute) (1.7.1)\n",
      "Collecting scs>=1.1.6\n",
      "  Downloading scs-3.2.3-cp37-cp37m-win_amd64.whl (8.2 MB)\n",
      "Collecting osqp>=0.4.1\n",
      "  Downloading osqp-0.6.3-cp37-cp37m-win_amd64.whl (292 kB)\n",
      "Collecting setuptools>65.5.1\n",
      "  Using cached setuptools-67.8.0-py3-none-any.whl (1.1 MB)\n",
      "Collecting ecos>=2\n",
      "  Downloading ecos-2.0.12-cp37-cp37m-win_amd64.whl (71 kB)\n",
      "Collecting qdldl\n",
      "  Downloading qdldl-0.1.7-cp37-cp37m-win_amd64.whl (83 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\debap\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pytest->fancyimpute) (21.2.0)\n",
      "Requirement already satisfied: iniconfig in c:\\users\\debap\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pytest->fancyimpute) (1.1.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\debap\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pytest->fancyimpute) (21.3)\n",
      "Requirement already satisfied: pluggy<1.0.0a1,>=0.12 in c:\\users\\debap\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pytest->fancyimpute) (0.13.1)\n",
      "Requirement already satisfied: py>=1.8.2 in c:\\users\\debap\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pytest->fancyimpute) (1.10.0)\n",
      "Requirement already satisfied: toml in c:\\users\\debap\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pytest->fancyimpute) (0.10.2)\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in c:\\users\\debap\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pytest->fancyimpute) (4.8.2)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in c:\\users\\debap\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pytest->fancyimpute) (1.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\debap\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pytest->fancyimpute) (0.4.6)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\debap\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.12->pytest->fancyimpute) (4.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\debap\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.12->pytest->fancyimpute) (3.6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\debap\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from packaging->pytest->fancyimpute) (3.0.4)\n",
      "Building wheels for collected packages: fancyimpute, knnimpute, cvxopt\n",
      "  Building wheel for fancyimpute (setup.py): started\n",
      "  Building wheel for fancyimpute (setup.py): finished with status 'done'\n",
      "  Created wheel for fancyimpute: filename=fancyimpute-0.7.0-py3-none-any.whl size=29899 sha256=b0ffb768aecde4f04dd3110f452535169a060dff31d90894b52806bd9890c1cf\n",
      "  Stored in directory: c:\\users\\debap\\appdata\\local\\pip\\cache\\wheels\\e3\\04\\06\\a1a7d89ef4e631ce6268ea2d8cde04f7290651c1ff1025ce68\n",
      "  Building wheel for knnimpute (setup.py): started\n",
      "  Building wheel for knnimpute (setup.py): finished with status 'done'\n",
      "  Created wheel for knnimpute: filename=knnimpute-0.1.0-py3-none-any.whl size=11353 sha256=0681c5d9bb6e1a9f6f3c606a7130237defbb8ad4e49d009ab78ab2f47cfa7283\n",
      "  Stored in directory: c:\\users\\debap\\appdata\\local\\pip\\cache\\wheels\\72\\21\\a8\\a045cacd9838abd5643f6bfa852c0796a99d6b1494760494e0\n",
      "  Building wheel for cvxopt (PEP 517): started\n",
      "  Building wheel for cvxopt (PEP 517): finished with status 'error'\n",
      "Successfully built fancyimpute knnimpute\n",
      "Failed to build cvxopt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  running build_ext\n",
      "  building 'base' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for cvxopt\n",
      "ERROR: Could not build wheels for cvxopt which use PEP 517 and cannot be installed directly\n"
     ]
    }
   ],
   "source": [
    " \n",
    " ! pip install fancyimpute   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1e9d510e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d35dd189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_dataframe(df):\n",
    "    imp = IterativeImputer(max_iter=10, random_state=0)\n",
    "    imp.fit(df)\n",
    "    imputed_df = pd.DataFrame(imp.transform(df), columns=df.columns)\n",
    "    return imputed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb3e2d3",
   "metadata": {},
   "source": [
    "## Ingesting the first week survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8b1ed90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['StartDate', 'EndDate', 'Status', 'IPAddress', 'Progress',\n",
      "       'Duration (in seconds)', 'Finished', 'RecordedDate', 'ResponseId',\n",
      "       'RecipientLastName', 'RecipientFirstName', 'RecipientEmail',\n",
      "       'ExternalReference', 'LocationLatitude', 'LocationLongitude',\n",
      "       'DistributionChannel', 'UserLanguage', 'Q52', 'Q48', 'Q1_1', 'Q1_2',\n",
      "       'Q1_3', 'Q1_4', 'Q1_5', 'Q1_6', 'Q1_7', 'Q1_8', 'Q1_9', 'Q1_10',\n",
      "       'Q1_11', 'Q1_12', 'Q1_13', 'Q1_14', 'Q1_15', 'Q1_16', 'Q2_1', 'Q2_2',\n",
      "       'Q2_3', 'Q2_4', 'Q2_5', 'Q2_6', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8',\n",
      "       'Q9', 'Q10', 'Q11', 'Q12', 'Q13', 'Q14', 'Q15', 'Q16', 'Q17', 'Q18',\n",
      "       'Q19', 'Q20', 'Q21', 'Q22', 'Q23', 'Q24', 'Q25', 'Q26', 'Q27', 'Q28',\n",
      "       'Q29', 'Q30', 'Q31', 'Q32', 'Q33', 'Q34', 'Q35', 'Q36', 'Q37', 'Q38',\n",
      "       'Q39', 'Q40', 'Q41', 'Q42', 'Q43', 'Q44', 'Q45', 'Q46'],\n",
      "      dtype='object')\n",
      "After removing first two rows: 788 Rows\n",
      " After Removing missing UINs :  778 Rows\n",
      " After removing rows with all the responses missing : 756 Rows\n",
      " After updating the missing values and removing irrelevant columns : (756, 69) Rows and columns\n",
      " After removing duplicates  : 747 Rows \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\debap\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:80: FutureWarning: The default value of regex will change from True to False in a future version.\n"
     ]
    }
   ],
   "source": [
    "first_week=pd.read_csv('SIIP+-+CS+173_February+7,+2023_13.45.csv')\n",
    "\n",
    "## Printing Columns \n",
    "\n",
    "print(first_week.columns)\n",
    "\n",
    "## Removing First Row \n",
    "\n",
    "\n",
    "first_row = first_week.iloc[:1]\n",
    "\n",
    "first_week = first_week.iloc[1:]\n",
    "\n",
    "## Creating a mapping file \n",
    "column_names = pd.DataFrame({'ColumnNames': first_week.columns})\n",
    "\n",
    "col_map = pd.concat([first_row.reset_index(drop=True), column_names], axis=0)\n",
    "\n",
    "## Removing Second Row \n",
    "\n",
    "first_week=first_week.reset_index(drop=True)\n",
    "first_week=first_week.iloc[1:]\n",
    "\n",
    "print('After removing first two rows: {} Rows'.format(first_week.shape[0]))\n",
    "\n",
    "## Removing Missing UINs and NetIDs\n",
    "\n",
    "\n",
    "first_week = first_week.dropna(subset=['Q48'])\n",
    "\n",
    "print(' After Removing missing UINs :  {} Rows'.format(first_week.shape[0]))\n",
    "\n",
    "## Checking for Missing values in questionaire columns \n",
    "\n",
    "columns_to_check = ['Q52', 'Q48', 'Q1_1', 'Q1_2',\n",
    "       'Q1_3', 'Q1_4', 'Q1_5', 'Q1_6', 'Q1_7', 'Q1_8', 'Q1_9', 'Q1_10',\n",
    "       'Q1_11', 'Q1_12', 'Q1_13', 'Q1_14', 'Q1_15', 'Q1_16', 'Q2_1', 'Q2_2',\n",
    "       'Q2_3', 'Q2_4', 'Q2_5', 'Q2_6', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8',\n",
    "       'Q9', 'Q10', 'Q11', 'Q12', 'Q13', 'Q14', 'Q15', 'Q16', 'Q17', 'Q18',\n",
    "       'Q19', 'Q20', 'Q21', 'Q22', 'Q23', 'Q24', 'Q25', 'Q26', 'Q27', 'Q28',\n",
    "       'Q29', 'Q30', 'Q31', 'Q32', 'Q33', 'Q34', 'Q35', 'Q36', 'Q37', 'Q38',\n",
    "       'Q39', 'Q40', 'Q41', 'Q42', 'Q43', 'Q44', 'Q45', 'Q46']\n",
    "\n",
    "missing_threshold = len(columns_to_check) / 2\n",
    "rows_with_missing_values = first_week[first_week[columns_to_check].isnull().sum(axis=1) > missing_threshold]\n",
    "\n",
    "first_week=first_week[~(first_week[columns_to_check].isnull().sum(axis=1) > missing_threshold)]\n",
    "\n",
    "print(' After removing rows with all the responses missing : {} Rows'.format(first_week.shape[0]))\n",
    "\n",
    "## Removing Irrelevant Columns \n",
    "\n",
    "# Define the list of column names to drop\n",
    "columns_to_drop = ['StartDate', 'Status', 'IPAddress', 'Progress',\n",
    "       'Duration (in seconds)', 'Finished', 'RecordedDate', 'ResponseId',\n",
    "       'RecipientLastName', 'RecipientFirstName', 'RecipientEmail',\n",
    "       'ExternalReference', 'LocationLatitude', 'LocationLongitude',\n",
    "       'DistributionChannel', 'UserLanguage']\n",
    "\n",
    "# Drop the columns from the dataframe\n",
    "first_week = first_week.drop(columns=columns_to_drop)\n",
    "\n",
    "#print(first_week.shape)\n",
    "## Replacing rows with missing values \n",
    "\n",
    "df_train=first_week.loc[:, ~first_week.columns.isin(['EndDate','Q48'])]\n",
    "#print(df_train.shape)\n",
    "end_date=pd.DataFrame(first_week[['EndDate','Q48']]).reset_index(drop=True)\n",
    "#print(end_date.shape)\n",
    "first_week=impute_dataframe(df_train)\n",
    "#print(first_week.shape)\n",
    "first_week=pd.concat([first_week,end_date],axis=1)\n",
    "#print(first_week.shape)\n",
    "#print(first_week.columns)\n",
    "\n",
    "print(' After updating the missing values and removing irrelevant columns : {} Rows and columns'.format(first_week.shape))\n",
    "\n",
    "### Removing @illinois.edu \n",
    "\n",
    "first_week['Q48'] = first_week['Q48'].str.replace('@illinois.edu', '')\n",
    "\n",
    "first_week = first_week.reset_index(drop=True)\n",
    "\n",
    "### Creating an isUIN Flag \n",
    "\n",
    "first_week['isUIN'] = first_week['Q48'].str.isnumeric()\n",
    "\n",
    "### Removing those without consent \n",
    "first_week['fw_consent'] = (first_week['Q52'] == 1).astype(int)\n",
    "\n",
    "### Updating Row Number and checking for duplicates\n",
    "\n",
    "first_week['EndDate'] = pd.to_datetime(first_week['EndDate'])\n",
    "\n",
    "first_week['rn'] = first_week.sort_values('EndDate').groupby('Q48').cumcount() + 1\n",
    "\n",
    "first_week = first_week.sort_values(['Q48', 'EndDate'])\n",
    "first_week['date_diff'] = first_week.groupby('Q48')['EndDate'].diff().dt.total_seconds() / 3600\n",
    "\n",
    "value_counts = first_week['Q48'].value_counts()\n",
    "first_week['isduplicate'] = first_week['Q48'].isin(value_counts[value_counts > 1].index)\n",
    "\n",
    "first_week = first_week[~((first_week['isduplicate'] == True) & (first_week['rn'] > 1) & (first_week['date_diff'] < 24))]\n",
    "\n",
    "first_week = first_week[((first_week['Q48'].duplicated(keep=False)) & (first_week['rn'] == 2)) | (~first_week['Q48'].duplicated(keep=False))]\n",
    "\n",
    "#first_week[['Q48','EndDate','fw_consent','date_diff','rn','isduplicate']].sort_values(['Q48', 'EndDate'])\n",
    "\n",
    "print(' After removing duplicates  : {} Rows '.format(first_week.shape[0]))\n",
    "\n",
    "## Updating the Q48 Column and creating a special flag \n",
    "\n",
    "first_week['Q48'] = first_week['Q48'].str.lower()\n",
    "first_week['IsName'] = ~first_week['Q48'].str.isalnum()\n",
    "\n",
    "first_week.to_csv('first_week.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361b9617",
   "metadata": {},
   "source": [
    "## Ingesting the Post Exam Surveys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "7f43a31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_columns(df, column_prefixes):\n",
    "    columns = [col for col in df.columns if any(col.startswith(prefix + ':') for prefix in column_prefixes)]\n",
    "    combined_column = df[columns].idxmax(axis=1).str.split(':').str[1].str.strip()\n",
    "    df[column_prefixes[0]] = combined_column\n",
    "    df = df.drop(columns=columns)\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# def combine_columns(df, column_prefix):\n",
    "#     columns = [col for col in df.columns if col.startswith(column_prefix)]\n",
    "#     combined_column = df[columns].idxmax(axis=1).str.split(':').str[0].str.strip()\n",
    "#     df[column_prefix] = combined_column\n",
    "#     df = df.drop(columns=columns)\n",
    "#     return df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "9dd71943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(875, 95)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\debap\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " After removing duplicates  from POE1 : 790 Rows \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\debap\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "C:\\Users\\debap\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:80: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "C:\\Users\\debap\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:81: FutureWarning: The default value of regex will change from True to False in a future version.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " After removing duplicates from POE2  : 781 Rows \n"
     ]
    }
   ],
   "source": [
    "poe1=pd.read_excel('cs173postexam1spring2023.xlsx')\n",
    "poe2=pd.read_excel('cs173postexam2spring2023.xlsx')\n",
    "#print(poe1.columns)\n",
    "print(poe2.shape)\n",
    "\n",
    "## Removing duplicates for POE1\n",
    "\n",
    "\n",
    "poe1['Submitted On'] = pd.to_datetime(poe1['Submitted On'])\n",
    "\n",
    "poe1['rn'] = poe1.sort_values('Submitted On').groupby('Logged in User ID').cumcount() + 1\n",
    "\n",
    "poe1 = poe1.sort_values(['Logged in User ID', 'Submitted On'])\n",
    "poe1['date_diff'] = poe1.groupby('Logged in User ID')['Submitted On'].diff().dt.total_seconds() / 3600\n",
    "\n",
    "value_counts = poe1['Logged in User ID'].value_counts()\n",
    "poe1['isduplicate'] = poe1['Logged in User ID'].isin(value_counts[value_counts > 1].index)\n",
    "\n",
    "poe1 = poe1[~((first_week['isduplicate'] == True) & (poe1['rn'] > 1) & (poe1['date_diff'] < 24))]\n",
    "\n",
    "poe1 = poe1[((poe1['Logged in User ID'].duplicated(keep=False)) & (poe1['rn'] == 2)) | (~poe1['Logged in User ID'].duplicated(keep=False))]\n",
    "\n",
    "#first_week[['Q48','EndDate','fw_consent','date_diff','rn','isduplicate']].sort_values(['Q48', 'EndDate'])\n",
    "\n",
    "print(' After removing duplicates  from POE1 : {} Rows '.format(poe1.shape[0]))\n",
    "\n",
    "\n",
    "\n",
    "## Removing duplicates for POE2 \n",
    "\n",
    "poe2['Submitted On'] = pd.to_datetime(poe2['Submitted On'])\n",
    "\n",
    "poe2['rn'] = poe2.sort_values('Submitted On').groupby('Logged in User ID').cumcount() + 1\n",
    "\n",
    "poe2 = poe2.sort_values(['Logged in User ID', 'Submitted On'])\n",
    "poe2['date_diff'] = poe2.groupby('Logged in User ID')['Submitted On'].diff().dt.total_seconds() / 3600\n",
    "\n",
    "value_counts = poe2['Logged in User ID'].value_counts()\n",
    "poe2['isduplicate'] = poe2['Logged in User ID'].isin(value_counts[value_counts > 1].index)\n",
    "\n",
    "poe2 = poe2[~((first_week['isduplicate'] == True) & (poe2['rn'] > 1) & (poe2['date_diff'] < 24))]\n",
    "\n",
    "poe2 = poe2[((poe2['Logged in User ID'].duplicated(keep=False)) & (poe2['rn'] == 2)) | (~poe2['Logged in User ID'].duplicated(keep=False))]\n",
    "\n",
    "#first_week[['Q48','EndDate','fw_consent','date_diff','rn','isduplicate']].sort_values(['Q48', 'EndDate'])\n",
    "\n",
    "print(' After removing duplicates from POE2  : {} Rows '.format(poe2.shape[0]))\n",
    "\n",
    "\n",
    "## Drop Columns \n",
    "\n",
    "columns_to_drop = ['Staff Illinois College/Unit Name', 'Staff Illinois College/Unit Name', 'date_diff']\n",
    "poe1 = poe1.drop(columns=columns_to_drop)\n",
    "poe2=poe2.drop(columns=columns_to_drop)\n",
    "#print(poe1.columns)\n",
    "\n",
    "\n",
    "## Update Columns for Poe1\n",
    "base_colname = 'Q'\n",
    "num_cols = 18\n",
    "columns = [f'{base_colname}{i+1}' for i in range(num_cols)]\n",
    "for col in columns:\n",
    "    #print(col)\n",
    "    poe1 = combine_columns(poe1, [col])\n",
    "    \n",
    "    \n",
    "## Update Columns for Poe2\n",
    "base_colname = 'Q'\n",
    "num_cols = 20\n",
    "columns = [f'{base_colname}{i+1}' for i in range(num_cols) if i != 18]\n",
    "for col in columns:\n",
    "    #print(col)\n",
    "    poe2 = combine_columns(poe2, [col])\n",
    "# print(poe1.columns)\n",
    "poe2.head()\n",
    "\n",
    "## Removing illinois.edu \n",
    "\n",
    "#first_week['Q48'] = first_week['Q48'].str.replace('@illinois.edu', '')\n",
    "poe1['Logged in User ID']=poe1['Logged in User ID'].str.replace('@illinois.edu', '')\n",
    "poe2['Logged in User ID']=poe2['Logged in User ID'].str.replace('@illinois.edu', '')\n",
    "\n",
    "## Renaming Columns in dataframe \n",
    "poe1.columns = 'poe1'+poe1.columns\n",
    "poe2.columns = 'poe2'+poe2.columns\n",
    "\n",
    "## Writing this to CSV \n",
    "poe1.to_csv('poe1.csv',index=False)\n",
    "poe2.to_csv('poe2.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca94677",
   "metadata": {},
   "source": [
    "## Grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "48a1f479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Net ID', 'UIN', 'Admit Term', 'Gender', 'Name', 'Email Address',\n",
      "       'Credit', 'Level', 'Year', 'Subject', 'Number', 'Section', 'CRN',\n",
      "       'Degree Name', 'Major 1 Name', 'College', 'Program Code',\n",
      "       'Program Name', 'FERPA', 'Honors Credit', 'raw grade', 'letter grade'],\n",
      "      dtype='object')\n",
      "Index(['UIN', 'Overall raw grade', 'Letter grade', 'netID', 'gender'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "final=pd.read_csv('CS_173_Spring2023_gradebook_FINAL.csv')\n",
    "midterm=pd.read_csv('CS_173_Spring2023_gradebook_MIDTERM.csv')\n",
    "\n",
    "print(final.columns)\n",
    "print(midterm.columns)\n",
    "\n",
    "final=final.drop('Honors Credit',axis=1)\n",
    "\n",
    "first_week=pd.read_csv('first_week.csv')\n",
    "poe1=pd.read_csv('poe1.csv')\n",
    "poe2=pd.read_csv('poe2.csv')\n",
    "demo=pd.read_excel('Data_UIN.xlsx')\n",
    "merit=pd.read_csv('meritstudents.csv')\n",
    "\n",
    "#first_week, poe1, poe2, midterm and final\n",
    "a = first_week[['Q48']].rename(columns={'Q48': 'netID'}).drop_duplicates()\n",
    "b = pd.DataFrame({'netID': poe1['poe1Logged in User ID'].unique()})\n",
    "c = pd.DataFrame({'netID': poe2['poe2Logged in User ID'].unique()})\n",
    "d = midterm[['netID']].drop_duplicates()\n",
    "e = pd.DataFrame({'netID': final['Net ID'].unique()})\n",
    "\n",
    "result = pd.concat([a, b, c, d, e]).drop_duplicates()\n",
    "\n",
    "first_week.columns = 'fw'+first_week.columns\n",
    "midterm.columns = 'mdt'+midterm.columns \n",
    "final.columns='final'+final.columns \n",
    "\n",
    "first_week['Isfw']=1\n",
    "poe1['IsPoe1']=1\n",
    "poe2['IsPoe2']=1\n",
    "midterm['Ismidterm']=1\n",
    "final['IsFinal']=1\n",
    "\n",
    "\n",
    "merged_df = pd.merge(result, first_week, left_on='netID', right_on='fwQ48', how='left')\n",
    "merged_df = pd.merge(merged_df, poe1, left_on='netID', right_on='poe1Logged in User ID', how='left')\n",
    "merged_df = pd.merge(merged_df, poe2, left_on='netID', right_on='poe2Logged in User ID', how='left')\n",
    "merged_df = pd.merge(merged_df, midterm, left_on='netID',right_on='mdtnetID', how='left')\n",
    "merged_df = pd.merge(merged_df, final, left_on='netID',right_on='finalNet ID', how='left')\n",
    "\n",
    "merged_df[['Isfw', 'IsPoe1', 'IsPoe2', 'Ismidterm', 'IsFinal']] = merged_df[['Isfw', 'IsPoe1', 'IsPoe2', 'Ismidterm', 'IsFinal']].fillna(0)\n",
    "\n",
    "## Adding demo and ismerit\n",
    "\n",
    "demo=pd.read_excel('Data_UIN.xlsx')\n",
    "merit=pd.read_csv('meritstudents.csv')\n",
    "merit.columns='mrt'+merit.columns\n",
    "demo.columns='dem'+demo.columns\n",
    "\n",
    "\n",
    "merged_df = pd.merge(merged_df, demo, left_on='finalUIN', right_on='demUIN', how='left')\n",
    "merged_df = pd.merge(merged_df, merit, left_on='finalUIN', right_on='mrtUIN', how='left')\n",
    "merged_df['IsMerit'] = np.where(merged_df['mrtUIN'].isnull(), 0, 1)\n",
    "\n",
    "\n",
    "cols = ['Isfw', 'IsPoe1', 'IsPoe2', 'Ismidterm', 'IsFinal','IsMerit'] + [col for col in merged_df.columns if col not in ['Isfw', 'IsPoe1', 'IsPoe2', 'Ismidterm', 'IsFinal','IsMerit']]\n",
    "merged_df = merged_df.reindex(columns=cols)\n",
    "\n",
    "\n",
    "\n",
    "merged_df.to_csv('cs173sp23masterdata.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "19f6e532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "861\n",
      "861\n",
      "861\n",
      "861\n"
     ]
    }
   ],
   "source": [
    "demo=pd.read_excel('Data_UIN.xlsx')\n",
    "merit=pd.read_csv('meritstudents.csv')\n",
    "merit.columns='mrt'+merit.columns\n",
    "demo.columns='dem'+demo.columns\n",
    "\n",
    "#merged_df['finalUIN'] = merged_df['finalUIN'].fillna(0)\n",
    "\n",
    "# Perform left join on merged_df and demo\n",
    "print(merged_df.shape[0])\n",
    "merged_df = pd.merge(merged_df, demo, left_on='finalUIN', right_on='demUIN', how='left')\n",
    "print(merged_df.shape[0])\n",
    "\n",
    "# Perform left join on result and merit\n",
    "print(merged_df.shape[0])\n",
    "merged_df = pd.merge(merged_df, merit, left_on='finalUIN', right_on='mrtUIN', how='left')\n",
    "print(merged_df.shape[0])\n",
    "# Create new column IsMerit using np.where\n",
    "merged_df['IsMerit'] = np.where(merged_df['mrtUIN'].isnull(), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "fab565c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    818\n",
       "1     43\n",
       "Name: IsMerit, dtype: int64"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "7a095a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Isfw',\n",
       " 'IsPoe1',\n",
       " 'IsPoe2',\n",
       " 'Ismidterm',\n",
       " 'IsFinal',\n",
       " 'netID',\n",
       " 'fwQ52',\n",
       " 'fwQ1_1',\n",
       " 'fwQ1_2',\n",
       " 'fwQ1_3',\n",
       " 'fwQ1_4',\n",
       " 'fwQ1_5',\n",
       " 'fwQ1_6',\n",
       " 'fwQ1_7',\n",
       " 'fwQ1_8',\n",
       " 'fwQ1_9',\n",
       " 'fwQ1_10',\n",
       " 'fwQ1_11',\n",
       " 'fwQ1_12',\n",
       " 'fwQ1_13',\n",
       " 'fwQ1_14',\n",
       " 'fwQ1_15',\n",
       " 'fwQ1_16',\n",
       " 'fwQ2_1',\n",
       " 'fwQ2_2',\n",
       " 'fwQ2_3',\n",
       " 'fwQ2_4',\n",
       " 'fwQ2_5',\n",
       " 'fwQ2_6',\n",
       " 'fwQ3',\n",
       " 'fwQ4',\n",
       " 'fwQ5',\n",
       " 'fwQ6',\n",
       " 'fwQ7',\n",
       " 'fwQ8',\n",
       " 'fwQ9',\n",
       " 'fwQ10',\n",
       " 'fwQ11',\n",
       " 'fwQ12',\n",
       " 'fwQ13',\n",
       " 'fwQ14',\n",
       " 'fwQ15',\n",
       " 'fwQ16',\n",
       " 'fwQ17',\n",
       " 'fwQ18',\n",
       " 'fwQ19',\n",
       " 'fwQ20',\n",
       " 'fwQ21',\n",
       " 'fwQ22',\n",
       " 'fwQ23',\n",
       " 'fwQ24',\n",
       " 'fwQ25',\n",
       " 'fwQ26',\n",
       " 'fwQ27',\n",
       " 'fwQ28',\n",
       " 'fwQ29',\n",
       " 'fwQ30',\n",
       " 'fwQ31',\n",
       " 'fwQ32',\n",
       " 'fwQ33',\n",
       " 'fwQ34',\n",
       " 'fwQ35',\n",
       " 'fwQ36',\n",
       " 'fwQ37',\n",
       " 'fwQ38',\n",
       " 'fwQ39',\n",
       " 'fwQ40',\n",
       " 'fwQ41',\n",
       " 'fwQ42',\n",
       " 'fwQ43',\n",
       " 'fwQ44',\n",
       " 'fwQ45',\n",
       " 'fwQ46',\n",
       " 'fwEndDate',\n",
       " 'fwQ48',\n",
       " 'fwisUIN',\n",
       " 'fwfw_consent',\n",
       " 'fwrn',\n",
       " 'fwdate_diff',\n",
       " 'fwisduplicate',\n",
       " 'fwIsName',\n",
       " 'poe1Logged in User ID',\n",
       " 'poe1Submitted On',\n",
       " 'poe1First Name',\n",
       " 'poe1Last Name',\n",
       " 'poe1Is Illinois Staff',\n",
       " 'poe1Staff Illinois Department Name',\n",
       " 'poe1Is Illinois Student',\n",
       " 'poe1Student Illinois College/Unit Name',\n",
       " 'poe1Student Illinois Department Name',\n",
       " 'poe1rn',\n",
       " 'poe1isduplicate',\n",
       " 'poe1Q1',\n",
       " 'poe1Q2',\n",
       " 'poe1Q3',\n",
       " 'poe1Q4',\n",
       " 'poe1Q5',\n",
       " 'poe1Q6',\n",
       " 'poe1Q7',\n",
       " 'poe1Q8',\n",
       " 'poe1Q9',\n",
       " 'poe1Q10',\n",
       " 'poe1Q11',\n",
       " 'poe1Q12',\n",
       " 'poe1Q13',\n",
       " 'poe1Q14',\n",
       " 'poe1Q15',\n",
       " 'poe1Q16',\n",
       " 'poe1Q17',\n",
       " 'poe1Q18',\n",
       " 'poe2Logged in User ID',\n",
       " 'poe2Submitted On',\n",
       " 'poe2First Name',\n",
       " 'poe2Last Name',\n",
       " 'poe2Is Illinois Staff',\n",
       " 'poe2Staff Illinois Department Name',\n",
       " 'poe2Is Illinois Student',\n",
       " 'poe2Student Illinois College/Unit Name',\n",
       " 'poe2Student Illinois Department Name',\n",
       " 'poe2Q19:What percentage of your time doing these activities was spent with other students?',\n",
       " 'poe2rn',\n",
       " 'poe2isduplicate',\n",
       " 'poe2Q1',\n",
       " 'poe2Q2',\n",
       " 'poe2Q3',\n",
       " 'poe2Q4',\n",
       " 'poe2Q5',\n",
       " 'poe2Q6',\n",
       " 'poe2Q7',\n",
       " 'poe2Q8',\n",
       " 'poe2Q9',\n",
       " 'poe2Q10',\n",
       " 'poe2Q11',\n",
       " 'poe2Q12',\n",
       " 'poe2Q13',\n",
       " 'poe2Q14',\n",
       " 'poe2Q15',\n",
       " 'poe2Q16',\n",
       " 'poe2Q17',\n",
       " 'poe2Q18',\n",
       " 'poe2Q20',\n",
       " 'mdtUIN',\n",
       " 'mdtOverall raw grade',\n",
       " 'mdtLetter grade',\n",
       " 'mdtnetID',\n",
       " 'mdtgender',\n",
       " 'finalNet ID',\n",
       " 'finalUIN',\n",
       " 'finalAdmit Term',\n",
       " 'finalGender',\n",
       " 'finalName',\n",
       " 'finalEmail Address',\n",
       " 'finalCredit',\n",
       " 'finalLevel',\n",
       " 'finalYear',\n",
       " 'finalSubject',\n",
       " 'finalNumber',\n",
       " 'finalSection',\n",
       " 'finalCRN',\n",
       " 'finalDegree Name',\n",
       " 'finalMajor 1 Name',\n",
       " 'finalCollege',\n",
       " 'finalProgram Code',\n",
       " 'finalProgram Name',\n",
       " 'finalFERPA',\n",
       " 'finalraw grade',\n",
       " 'finalletter grade']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(merged_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "245d3883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['EDW_PERS_ID', 'UIN', 'FirstName', 'MiddleName', 'LastName', 'Gender',\n",
      "       'Race', 'Stu_Attr', 'UnderRepDomestic', 'PermAddr1', 'PermCity',\n",
      "       'PermState', 'PermZip', 'PermCountry', 'Duplicated EDW_PERS_ID',\n",
      "       'TechGPA'],\n",
      "      dtype='object')\n",
      "#######################\n",
      "Index(['Unnamed: 0', 'UIN'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(demo.columns)\n",
    "print('#######################')\n",
    "print(merit.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc90085a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "1bb4c726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Q52', 'Q1_1', 'Q1_2', 'Q1_3', 'Q1_4', 'Q1_5', 'Q1_6', 'Q1_7', 'Q1_8',\n",
       "       'Q1_9', 'Q1_10', 'Q1_11', 'Q1_12', 'Q1_13', 'Q1_14', 'Q1_15', 'Q1_16',\n",
       "       'Q2_1', 'Q2_2', 'Q2_3', 'Q2_4', 'Q2_5', 'Q2_6', 'Q3', 'Q4', 'Q5', 'Q6',\n",
       "       'Q7', 'Q8', 'Q9', 'Q10', 'Q11', 'Q12', 'Q13', 'Q14', 'Q15', 'Q16',\n",
       "       'Q17', 'Q18', 'Q19', 'Q20', 'Q21', 'Q22', 'Q23', 'Q24', 'Q25', 'Q26',\n",
       "       'Q27', 'Q28', 'Q29', 'Q30', 'Q31', 'Q32', 'Q33', 'Q34', 'Q35', 'Q36',\n",
       "       'Q37', 'Q38', 'Q39', 'Q40', 'Q41', 'Q42', 'Q43', 'Q44', 'Q45', 'Q46',\n",
       "       'EndDate', 'Q48', 'isUIN', 'fw_consent', 'rn', 'date_diff',\n",
       "       'isduplicate', 'IsName'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_week.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "901cfeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "681037aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=pd.DataFrame(result)\n",
    "result.columns=['netID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "45f3caee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fwQ52</th>\n",
       "      <th>fwQ1_1</th>\n",
       "      <th>fwQ1_2</th>\n",
       "      <th>fwQ1_3</th>\n",
       "      <th>fwQ1_4</th>\n",
       "      <th>fwQ1_5</th>\n",
       "      <th>fwQ1_6</th>\n",
       "      <th>fwQ1_7</th>\n",
       "      <th>fwQ1_8</th>\n",
       "      <th>fwQ1_9</th>\n",
       "      <th>...</th>\n",
       "      <th>fwQ46</th>\n",
       "      <th>fwEndDate</th>\n",
       "      <th>fwQ48</th>\n",
       "      <th>fwisUIN</th>\n",
       "      <th>fwfw_consent</th>\n",
       "      <th>fwrn</th>\n",
       "      <th>fwdate_diff</th>\n",
       "      <th>fwisduplicate</th>\n",
       "      <th>fwIsName</th>\n",
       "      <th>Isfw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28-01-2023 22:42</td>\n",
       "      <td>xl137</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27-01-2023 02:31</td>\n",
       "      <td>ezrajc2</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30-01-2023 21:09</td>\n",
       "      <td>jlope262</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27-01-2023 15:03</td>\n",
       "      <td>hl87</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28-01-2023 14:47</td>\n",
       "      <td>hannac4</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   fwQ52  fwQ1_1  fwQ1_2  fwQ1_3  fwQ1_4  fwQ1_5  fwQ1_6  fwQ1_7  fwQ1_8  \\\n",
       "0      4       3       3       3       3       3       3       3       3   \n",
       "1      1       4       5       4       2       4       3       5       1   \n",
       "2      1       3       3       3       3       5       5       4       4   \n",
       "3      1       1       5       5       1       5       5       1       5   \n",
       "4      1       2       3       3       2       3       4       4       2   \n",
       "\n",
       "   fwQ1_9  ...  fwQ46         fwEndDate     fwQ48  fwisUIN  fwfw_consent  \\\n",
       "0       3  ...    1.0  28-01-2023 22:42     xl137    False             0   \n",
       "1       5  ...    1.0  27-01-2023 02:31   ezrajc2     True             1   \n",
       "2       4  ...    1.0  30-01-2023 21:09  jlope262     True             1   \n",
       "3       1  ...    1.0  27-01-2023 15:03      hl87     True             1   \n",
       "4       3  ...    1.0  28-01-2023 14:47   hannac4     True             1   \n",
       "\n",
       "   fwrn  fwdate_diff  fwisduplicate  fwIsName  Isfw  \n",
       "0     1          NaN          False      True     1  \n",
       "1     1          NaN          False     False     1  \n",
       "2     1          NaN          False     False     1  \n",
       "3     1          NaN          False     False     1  \n",
       "4     1          NaN          False     False     1  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "b8676d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['netID', 'poe1Logged in User ID', 'poe1Submitted On', 'poe1First Name',\n",
       "       'poe1Last Name', 'poe1Is Illinois Staff',\n",
       "       'poe1Staff Illinois Department Name', 'poe1Is Illinois Student',\n",
       "       'poe1Student Illinois College/Unit Name',\n",
       "       'poe1Student Illinois Department Name', 'poe1rn', 'poe1isduplicate',\n",
       "       'poe1Q1', 'poe1Q2', 'poe1Q3', 'poe1Q4', 'poe1Q5', 'poe1Q6', 'poe1Q7',\n",
       "       'poe1Q8', 'poe1Q9', 'poe1Q10', 'poe1Q11', 'poe1Q12', 'poe1Q13',\n",
       "       'poe1Q14', 'poe1Q15', 'poe1Q16', 'poe1Q17', 'poe1Q18', 'IsPoe1',\n",
       "       'poe2Logged in User ID', 'poe2Submitted On', 'poe2First Name',\n",
       "       'poe2Last Name', 'poe2Is Illinois Staff',\n",
       "       'poe2Staff Illinois Department Name', 'poe2Is Illinois Student',\n",
       "       'poe2Student Illinois College/Unit Name',\n",
       "       'poe2Student Illinois Department Name',\n",
       "       'poe2Q19:What percentage of your time doing these activities was spent with other students?',\n",
       "       'poe2rn', 'poe2isduplicate', 'poe2Q1', 'poe2Q2', 'poe2Q3', 'poe2Q4',\n",
       "       'poe2Q5', 'poe2Q6', 'poe2Q7', 'poe2Q8', 'poe2Q9', 'poe2Q10', 'poe2Q11',\n",
       "       'poe2Q12', 'poe2Q13', 'poe2Q14', 'poe2Q15', 'poe2Q16', 'poe2Q17',\n",
       "       'poe2Q18', 'poe2Q20', 'IsPoe2', 'mdtUIN', 'mdtOverall raw grade',\n",
       "       'mdtLetter grade', 'mdtnetID', 'mdtgender', 'Ismidterm', 'finalNet ID',\n",
       "       'finalUIN', 'finalAdmit Term', 'finalGender', 'finalName',\n",
       "       'finalEmail Address', 'finalCredit', 'finalLevel', 'finalYear',\n",
       "       'finalSubject', 'finalNumber', 'finalSection', 'finalCRN',\n",
       "       'finalDegree Name', 'finalMajor 1 Name', 'finalCollege',\n",
       "       'finalProgram Code', 'finalProgram Name', 'finalFERPA',\n",
       "       'finalraw grade', 'finalletter grade', 'IsFinal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "e606d208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_difference(df1: pd.DataFrame, col1: str, df2: pd.DataFrame, col2: str) -> list:\n",
    "    difference = set(df1[col1]) - set(df2[col2])\n",
    "    return list(difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "9ae4b0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "print(len(get_difference(final,'Net ID',midterm,'netID'))) \n",
    "print(len(get_difference(midterm,'netID',final,'Net ID'))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "edc10313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(get_difference(poe1,'poe1Logged in User ID',poe2,'poe2Logged in User ID')) ## 33\n",
    "len(get_difference(poe2,'poe2Logged in User ID',poe1,'poe1Logged in User ID')) ## 24 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "d1a98570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Q52', 'Q1_1', 'Q1_2', 'Q1_3', 'Q1_4', 'Q1_5', 'Q1_6', 'Q1_7', 'Q1_8',\n",
       "       'Q1_9', 'Q1_10', 'Q1_11', 'Q1_12', 'Q1_13', 'Q1_14', 'Q1_15', 'Q1_16',\n",
       "       'Q2_1', 'Q2_2', 'Q2_3', 'Q2_4', 'Q2_5', 'Q2_6', 'Q3', 'Q4', 'Q5', 'Q6',\n",
       "       'Q7', 'Q8', 'Q9', 'Q10', 'Q11', 'Q12', 'Q13', 'Q14', 'Q15', 'Q16',\n",
       "       'Q17', 'Q18', 'Q19', 'Q20', 'Q21', 'Q22', 'Q23', 'Q24', 'Q25', 'Q26',\n",
       "       'Q27', 'Q28', 'Q29', 'Q30', 'Q31', 'Q32', 'Q33', 'Q34', 'Q35', 'Q36',\n",
       "       'Q37', 'Q38', 'Q39', 'Q40', 'Q41', 'Q42', 'Q43', 'Q44', 'Q45', 'Q46',\n",
       "       'EndDate', 'Q48', 'isUIN', 'fw_consent', 'rn', 'date_diff',\n",
       "       'isduplicate', 'IsName'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_week=pd.read_csv('first_week.csv')\n",
    "first_week.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "5d2b08e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(get_difference(poe1,'poe1Logged in User ID',first_week,'Q48')) ## 102 \n",
    "len(get_difference(first_week,'Q48',poe1,'poe1Logged in User ID')) ## 59 \n",
    "#len(get_difference(poe2,'poe2Logged in User ID',poe1,'poe1Logged in User ID')) ## 24 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "95fab1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(get_difference(poe2,'poe2Logged in User ID',first_week,'Q48')) ## 98  \n",
    "len(get_difference(first_week,'Q48',poe2,'poe2Logged in User ID')) ## 64  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "a067a647",
   "metadata": {},
   "outputs": [],
   "source": [
    "poe1.to_csv('poe1.csv')\n",
    "poe2.to_csv('poe2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "63b74896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "409                 > 3 hours\n",
       "721    > 1 hour but < 3 hours\n",
       "288                  < 1 hour\n",
       "382               Did not use\n",
       "392    > 1 hour but < 3 hours\n",
       "                ...          \n",
       "268    > 1 hour but < 3 hours\n",
       "620    > 1 hour but < 3 hours\n",
       "163    > 1 hour but < 3 hours\n",
       "8                   > 3 hours\n",
       "206                 > 3 hours\n",
       "Length: 790, dtype: object"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "969fef5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 > 3 hours\n",
       "1    > 1 hour but < 3 hours\n",
       "2                  < 1 hour\n",
       "3               Did not use\n",
       "4    > 1 hour but < 3 hours\n",
       "Name: Q1, dtype: object"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poe1.Q1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69a8a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
